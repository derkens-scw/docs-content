---
meta:
  title: Leverage on NATS Messaging Pub/Sub capabilities to offload your Managed Database.
  description: Learn how to construct a pub/sub architecture that can help you manage the load coming to your database. Dive into this Python tutorial for step-by-step guidance on asynchronous data processing.
content:
  h1: CLeverage on NATS Messaging Pub/Sub capabilities to offload your Managed Database.
  paragraph: Learn how to construct a pub/sub architecture that can help you manage the load coming to your database. Dive into this Python tutorial for step-by-step guidance on asynchronous data processing.
categories:
  - functions
  - messaging
  - postgresql-and-mysql
tags: terraform scraping-architecture
dates:
  validation: 
  posted: 
---

## Introduction

In this tutorial, we show how to set up a system that receives a message from a publisher and sends it to a managed database through a buffer subscriber. To do so, we  use Scaleway serverless products and deploy two applications:
 - A publisher application, that sends a message to a NATS stream created with Scaleway Messaging and Queuing.
 - A subscriber application, that consumes messages published to the stream and then writes the data into a Scaleway Managed Database.

<Lightbox src="scaleway-scraping-architecture.webp" alt="" />

We show how to provision all the required Scaleway resources using code examples and Scaleway Console [console](https://console.scaleway.com/). The code for the functions is written in Python.

This project exemplifies a decoupled architecture, where producer and consumer perform specific tasks independently. This kind of design is modular and allows for flexibility and scalability. It also adheres to the principles of microservices and serverless architectures, where individual functions or scripts focus on specific tasks.

To properly follow this tutorial, we recommend you to create a dedicated project in your Scaleway account.
You can name it "RDB & NATS Tutorial". It will hold all your Scaleway ressources created for this tutorial, they will be easier to find.

<Macro id="requirements" />

- A Scaleway account logged into the [console](https://console.scaleway.com)
- [Owner](/identity-and-access-management/iam/concepts/#owner) status or [IAM permissions](/identity-and-access-management/iam/concepts/#permission) allowing you to perform actions in the intended Organization
- Installed [NATS CLI](https://github.com/nats-io/natscli) on your local machine
- Generated NATS Credentials
- Created RDB (https://www.scaleway.com/en/docs/managed-databases/postgresql-and-mysql/quickstart/)


## Create a NATS server

You can refer to the following documentation (https://www.scaleway.com/en/docs/serverless/messaging/api-cli/nats-cli/) to create your NATS stream.
For the stream specifications, we recommend you to be as minimalist as possible. 
There is no need for replication or specific parameters for this tutorial.

Once you followed the abovementionned documentation, follow the next steps to set up your nats broker
1. Open a Terminal window 
2. Go to your directory for the project
3. Run your NATS server by using the following code 
    ```
    nats-server

    ```
You now have your NATS server up and running.
To be sure we did not forgot anything for the Scaleway context, paste the following code in your terminal
    ```
    nats context info scaleway  
    ```
You should see "OK" mentionned for the credentials path and that your NATS server is ready!
If not go back to the NATS CLI documentation to create properly a Scaleway context.

<add screenshot of NATS information>

## Install the dependencies

1. Open a new Terminal window from your project directory
2. Install the following dependencies for the tutorial
    ```
    sudo apt-get install mysql-server
    pip install mysql-connector-python 
    pip install pynacl
    pip install nkeys
    ```


## Connect to your Scalesway RDB

1. Open a new Terminal window
2. Go to Scaleway Console and into your project
3. Go to your mySQL database 
4. Go to Overview
5. Use the snippet under Connection into the Network bloc so you can connect
6. Copy the snippet into the Terminal window and update it with your created username
7. Follow the instructions in the terminal to validate your password
8. You should have an access to mysql environment 

<add screenshot of sql terminal>

## Create the publisher

We start by creating the publisher application.
1. Create a new file in your project directory named nats_publisher.py
2. Paste the following Python code in the file
    ```
import asyncio
from nats.aio.client import Client as NATS

async def run_publisher():
    # Connect to the NATS server
    nc = NATS()

    await nc.connect("NATS ACCOUNT URL", user_credentials="NATS CREDENTIALS PATH")

    # Publish a message to the subject
    await nc.publish("foo", b'Hello, World!')

    # Flush to ensure messages are processed
    await nc.flush()

    # Close the connection
    await nc.close()

if __name__ == '__main__':
    asyncio.run(run_publisher())
    ```
3. Update the code with your NATS information

This small Python application will publish a "Hello World!" message under the "foo" subject

## Create the subscriber

We start by creating the subscriber application.
1. Create a new file in your project directory named nats_subscriber_with_mysql.py
2. Paste the following Python code in the file
    ```
import asyncio
import mysql.connector
from nats.aio.client import Client as NATS

async def run_subscriber():
    # Connect to the NATS server
    nc = NATS()

    await nc.connect("NATS ACCOUNT URL", user_credentials="NATS CREDENTIALS PATH")

    async def message_handler(msg):
        subject = msg.subject
        data = msg.data.decode()
        print(f"Received a message on '{subject}': {data}")

        # Store the message in the MySQL database
        conn = mysql.connector.connect(
            host="PUBLIC ENDPOINT",
            port="PORT",
            user="NAME",
            password="PASSWORD",
            database="nats_messages"
        )
        cursor = conn.cursor()
        cursor.execute('INSERT INTO messages (subject, data) VALUES (%s, %s)', (subject, data))
        conn.commit()
        cursor.close()
        conn.close()

    # Subscribe to a subject
    await nc.subscribe("foo", cb=message_handler)

    # Keep the subscriber running to receive messages
    while True:
        await asyncio.sleep(1)

if __name__ == '__main__':
    asyncio.run(run_subscriber())
```
3. Update the subscriber code with your Scaleway RDB information as well as the ones form your NATS.
   You will note that they are the same as the publisher's. 
   It's completely normal as both applications are communicating through the same NATS server.




## Put it all in motion
Terraform makes this very straightforward. To provision all the resources and get everything up and running, run the following commands:
```
cd terraform
terraform init
terraform plan 
terraform apply
```

### How to check that everything is working correctly

Go to the [Scaleway console](https://console.scaleway.com/), and check the logs and metrics for Serverless Functions' execution and Messaging and Queuing SQS queue statistics.

To make sure the data is correctly stored in the database, you can [connect to it directly](/managed-databases/postgresql-and-mysql/how-to/connect-database-instance/) via a CLI tool such as `psql`. 
Retrieve the instance IP and port of your Managed Database from the console, under the [Managed Database section](https://console.scaleway.com/rdb/instances).
Use the following command to connect to your database. When prompted for a password, you can find it by running `terraform output -json`.
```
psql -h <DB_INSTANCE_IP> --port <DB_INSTANCE_PORT> -d hn-database -U worker
```

When you are done testing, don't forget to clean up! To do so, run: 
```
cd terraform
terraform destroy
```

## Summary, going further, key takeaways
We have shown how to asynchronously decouple the producer and the consumer using SQS, adhering to serverless patterns.

While the volume of data processed in this example is quite small, thanks to the Messaging and Queuing SQS queue's robustness and the auto-scaling capabilities of the Serverless Functions, you can adapt this example to manage larger workloads.

Here are some possible extensions to this basic example:
 - Replace the simple proposed logic with your own. What about counting how many times some keywords (e.g: copilot, serverless, microservice) appear in Hacker News articles? 
 - Define multiple cron triggers for different websites and pass the website as an argument to the function. Or, create multiple functions that feed the same queue.
 - Use a [Serverless Container](/serverless/containers/quickstart/) instead of the consumer function, and use a command line tool such as `htmldoc` or `pandoc` to convert the scraped articles to PDF and upload the result to a [Scaleway Object Storage](/storage/object/quickstart/) S3 bucket.
 - Replace the Managed Database for PostgreSQL with a [Scaleway Serverless Database](/serverless/sql-databases/quickstart/), so that all the infrastructure lives in the serverless ecosystem! *Note that at the moment there is no Terraform support for Serverless Database, hence the choice here to use Managed Database for PostgreSQL*.
